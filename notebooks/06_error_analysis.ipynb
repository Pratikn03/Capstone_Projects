{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a71f223",
   "metadata": {},
   "source": [
    "# Error Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4036eeb7",
   "metadata": {},
   "source": [
    "## Notebook Guide\n",
    "\n",
    "- **Purpose:** Analyze residuals and error patterns; highlight anomalies.\n",
    "- **Inputs:** data/processed/splits/*.parquet + trained models\n",
    "- **Outputs:** residual charts and anomaly flags.\n",
    "- **Run:** Execute cells top‑to‑bottom. If a file is missing, run the earlier pipeline notebook first.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5baa4d9",
   "metadata": {},
   "source": [
    "Residual analysis for GBM predictions by hour and day-of-week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print('Python:', sys.executable)\n",
    "repo_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "subprocess.run(['pip', 'install', '-e', str(repo_root)], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, pickle\n",
    "\n",
    "train = pd.read_parquet('data/processed/splits/train.parquet')\n",
    "val = pd.read_parquet('data/processed/splits/val.parquet')\n",
    "test = pd.read_parquet('data/processed/splits/test.parquet')\n",
    "\n",
    "# Load GBM model bundle\n",
    "bundle = pickle.load(open('artifacts/models/gbm_lightgbm_load_mw.pkl', 'rb'))\n",
    "model = bundle['model']\n",
    "feat_cols = bundle['feature_cols']\n",
    "\n",
    "X = test[feat_cols].to_numpy()\n",
    "y = test['load_mw'].to_numpy()\n",
    "pred = model.predict(X)\n",
    "resid = y - pred\n",
    "\n",
    "err = test[['timestamp']].copy()\n",
    "err['resid'] = resid\n",
    "err['hour'] = pd.to_datetime(err['timestamp']).dt.hour\n",
    "err['dow'] = pd.to_datetime(err['timestamp']).dt.dayofweek\n",
    "\n",
    "err.groupby('hour')['resid'].mean().plot(title='Mean Residual by Hour')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd07590d",
   "metadata": {},
   "source": [
    "## Visual Sanity Checks\n",
    "\n",
    "These plots provide a quick visual validation of recent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6001389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "repo_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "features_path = repo_root / 'data' / 'processed' / 'features.parquet'\n",
    "if not features_path.exists():\n",
    "    print('features.parquet not found. Run the feature pipeline first.')\n",
    "else:\n",
    "    df_viz = pd.read_parquet(features_path).sort_values('timestamp')\n",
    "    if {'load_mw','wind_mw','solar_mw'}.issubset(df_viz.columns):\n",
    "        recent = df_viz.tail(7 * 24)\n",
    "        fig, ax = plt.subplots(3, 1, figsize=(12, 7), sharex=True)\n",
    "        recent.plot(x='timestamp', y='load_mw', ax=ax[0], color='#1f77b4', title='Load (last 7 days)')\n",
    "        recent.plot(x='timestamp', y='wind_mw', ax=ax[1], color='#2ca02c', title='Wind (last 7 days)')\n",
    "        recent.plot(x='timestamp', y='solar_mw', ax=ax[2], color='#ff7f0e', title='Solar (last 7 days)')\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        print('Expected columns not found in features.parquet')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
