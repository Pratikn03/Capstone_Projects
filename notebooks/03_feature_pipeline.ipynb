{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63800fa7",
   "metadata": {},
   "source": [
    "# Feature Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6b9ae",
   "metadata": {},
   "source": [
    "Run the full data pipeline and inspect engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a3c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print('Python:', sys.executable)\n",
    "repo_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "subprocess.run(['pip', 'install', '-e', str(repo_root)], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "repo_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "raw_csv = repo_root / 'data' / 'raw' / 'time_series_60min_singleindex.csv'\n",
    "if not raw_csv.exists():\n",
    "    nested = next((repo_root / 'data' / 'raw').glob('opsd-time_series-*/time_series_60min_singleindex.csv'), None)\n",
    "    if nested:\n",
    "        raw_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy(nested, raw_csv)\n",
    "        print('Copied:', nested, '->', raw_csv)\n",
    "    else:\n",
    "        print('Missing OPSD CSV. Please download or place it in data/raw/')\n",
    "print('Raw CSV:', raw_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\n",
    "    'python', '-m', 'gridpulse.data_pipeline.validate_schema',\n",
    "    '--in', 'data/raw', '--report', 'reports/data_quality_report.md'\n",
    "], check=True, cwd=str(repo_root))\n",
    "\n",
    "subprocess.run([\n",
    "    'python', '-m', 'gridpulse.data_pipeline.build_features',\n",
    "    '--in', 'data/raw', '--out', 'data/processed'\n",
    "], check=True, cwd=str(repo_root))\n",
    "\n",
    "subprocess.run([\n",
    "    'python', '-m', 'gridpulse.data_pipeline.split_time_series',\n",
    "    '--in', 'data/processed/features.parquet',\n",
    "    '--out', 'data/processed/splits'\n",
    "], check=True, cwd=str(repo_root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "features_path = Path(repo_root) / 'data' / 'processed' / 'features.parquet'\n",
    "print('Features path:', features_path)\n",
    "\n",
    "if not features_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing {features_path}. Run the pipeline cell above.\")\n",
    "\n",
    "df = pd.read_parquet(features_path)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}